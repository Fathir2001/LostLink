# Environment
ENV=development
HOST=0.0.0.0
PORT=8000

# GPU Settings
CUDA_VISIBLE_DEVICES=0
USE_GPU=true

# Model Settings
# Embedding model (sentence-transformers)
EMBEDDING_MODEL=all-MiniLM-L6-v2
# For better quality (larger, slower): all-mpnet-base-v2

# Vision model for object detection
VISION_MODEL=facebook/detr-resnet-50
# Alternative: google/owlvit-base-patch32

# LLM for extraction (can use local or API)
LLM_MODEL=local
# Options: local, openai, ollama
# For local: uses a small instruction-tuned model
# For openai: requires OPENAI_API_KEY (not $0 budget!)

# Local LLM (if LLM_MODEL=local)
LOCAL_LLM=microsoft/phi-2
# Alternatives:
# - TinyLlama/TinyLlama-1.1B-Chat-v1.0 (smaller)
# - mistralai/Mistral-7B-Instruct-v0.1 (better but needs more VRAM)

# OCR Settings
OCR_LANGUAGES=en

# Cache Settings
CACHE_DIR=./cache
MODEL_CACHE_DIR=./models

# Rate Limiting
MAX_REQUESTS_PER_MINUTE=60
MAX_IMAGE_SIZE_MB=10

# CORS
ALLOWED_ORIGINS=http://localhost:3000,http://localhost:3001
